{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before launching jupyter and this notebook, type in terminal: \n",
    "\n",
    "source activate nbodykit-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbodykit.lab import *\n",
    "from nbodykit import setup_logging, style\n",
    "from nbodykit.algorithms.fftpower import project_to_basis\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(style.notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging() # turn on logging to screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FKP norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compte the normalization of the FKP estimator. \n",
    "\n",
    "My strategy is to call exactly the same functions from *nbodykit* that are called when computing the power spectrum so that we are assured that we get the right answer: after all, we already computed the right normalization, $A_{s\\rightarrow0}$, taking the $s\\rightarrow 0$ limit of the window function that is simply the Fourier transform of the power spectrum of the randoms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the definitions for the FKP normalization we know:\n",
    "\\begin{align}\n",
    "A & \\equiv \\int d^3 r \\ n_w(r)^2 \\\\\n",
    "A_{s\\rightarrow 0} & = \\lim_{s\\rightarrow 0} Q(s) = \\lim_{s\\rightarrow 0} \\int d^3 r \\ n_w(r) n_w(r-s)\\\\\n",
    "A_{k \\rightarrow 0} & = \\lim_{k\\rightarrow 0} \\int d^3 r \\ e^{-ikr} n_w(r)^2 \\ ,\n",
    "\\end{align}\n",
    "where $n_w \\equiv n \\cdot w$ is a shorthand. \n",
    "\n",
    "We already computed $A_{s\\rightarrow 0}$. Let us try $A_{k \\rightarrow 0}$. \n",
    "\n",
    "\\begin{align}\n",
    "A_{k \\rightarrow 0} & = \\lim_{k\\rightarrow 0} \\int d^3 r \\ e^{-ikr} n_w(r)^2 \\\\\n",
    " & = \\lim_{k\\rightarrow 0} \\int d^3 p \\ \\tilde n_w(p+k) \\tilde n_w(p) \\\\\n",
    " & = \\int d^3 p \\ \\tilde n_w(p)^2 \\ ,\n",
    "\\end{align}\n",
    "where we use the convolution theorem at second line, with $\\tilde n_w(p) = \\int d^3 r \\ e^{-ipr} n_w(r)$. \n",
    "\n",
    "So in fact we can now see the relationship between the two definitions: \n",
    "\\begin{align}\n",
    "A_{s\\rightarrow 0} & = \\lim_{s\\rightarrow 0} \\int d^3 p \\ e^{iks} \\tilde n_w(p)^2 \\\\\n",
    " & = \\lim_{s\\rightarrow 0} \\int d^3 r \\ n_w(r-s) n_w(r) \\\\\n",
    " & = \\int d^3 r \\ n_w(r)^2 \\ ,\n",
    "\\end{align}\n",
    "using once again the convolution theorem at second line, with $n_w(r) = \\int d^3 p \\ e^{ipr} \\tilde n_w(p)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting BOSS catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_download_progress(count, block_size, total_size):\n",
    "    import sys\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_data(download_dir):\n",
    "    \"\"\"\n",
    "    Download the FITS data needed for this notebook to the specified directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    download_dir : str\n",
    "        the data will be downloaded to this directory\n",
    "    \"\"\"\n",
    "    from six.moves import urllib\n",
    "    import shutil\n",
    "    import gzip\n",
    "    \n",
    "#     urls = ['https://data.sdss.org/sas/dr12/boss/lss/galaxy_DR12v5_LOWZ_South.fits.gz',\n",
    "#             'https://data.sdss.org/sas/dr12/boss/lss/random0_DR12v5_LOWZ_South.fits.gz']\n",
    "#     filenames = ['galaxy_DR12v5_LOWZ_South.fits', 'random0_DR12v5_LOWZ_South.fits']\n",
    "#     urls = ['https://data.sdss.org/sas/dr12/boss/lss/galaxy_DR12v5_CMASS_North.fits.gz',\n",
    "#             'https://data.sdss.org/sas/dr12/boss/lss/random0_DR12v5_CMASS_North.fits.gz']\n",
    "#     filenames = ['galaxy_DR12v5_CMASS_North.fits', 'random0_DR12v5_CMASS_North.fits']\n",
    "    urls = ['https://data.sdss.org/sas/dr12/boss/lss/random0_DR12v5_CMASSLOWZTOT_North.fits.gz',\n",
    "            'https://data.sdss.org/sas/dr12/boss/lss/random0_DR12v5_CMASSLOWZTOT_South.fits.gz',\n",
    "            'https://data.sdss.org/sas/dr12/boss/lss/galaxy_DR12v5_CMASSLOWZTOT_North.fits.gz',\n",
    "            'https://data.sdss.org/sas/dr12/boss/lss/galaxy_DR12v5_CMASSLOWZTOT_South.fits.gz']\n",
    "    filenames = ['random0_DR12v5_CMASSLOWZTOT_North.fits', \n",
    "                 'random0_DR12v5_CMASSLOWZTOT_South.fits',\n",
    "                 'galaxy_DR12v5_CMASSLOWZTOT_North.fits', \n",
    "                 'galaxy_DR12v5_CMASSLOWZTOT_South.fits']\n",
    "    \n",
    "    # download both files\n",
    "    for i, url in enumerate(urls):\n",
    "        \n",
    "        # the download path\n",
    "        filename = url.split('/')[-1]\n",
    "        file_path = os.path.join(download_dir, filename)\n",
    "        final_path = os.path.join(download_dir, filenames[i])\n",
    "        \n",
    "        # do not re-download\n",
    "        if not os.path.exists(final_path):\n",
    "            print(\"Downloading %s\" % url)\n",
    "            \n",
    "            # Check if the download directory exists, otherwise create it.\n",
    "            if not os.path.exists(download_dir):\n",
    "                os.makedirs(download_dir)\n",
    "\n",
    "            # Download the file from the internet.\n",
    "            file_path, _ = urllib.request.urlretrieve(url=url,\n",
    "                                                      filename=file_path,\n",
    "                                                      reporthook=print_download_progress)\n",
    "\n",
    "            print()\n",
    "            print(\"Download finished. Extracting files.\")\n",
    "\n",
    "            # unzip the file\n",
    "            with gzip.open(file_path, 'rb') as f_in, open(final_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "            os.remove(file_path)\n",
    "            print(\"Done.\")\n",
    "        else:\n",
    "            print(\"Data has already been downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://data.sdss.org/sas/dr12/boss/lss/random0_DR12v5_CMASSLOWZTOT_North.fits.gz\n",
      "- Download progress: 1.8%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-87ad1f50f100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# download the data to the current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"catalogs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-461cbb1fe6df>\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(download_dir)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Download the file from the internet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             file_path, _ = urllib.request.urlretrieve(url=url,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                                       \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                                       reporthook=print_download_progress)\n",
      "\u001b[0;32m~/.conda/envs/nbodykit-env/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nbodykit-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nbodykit-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nbodykit-env/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nbodykit-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nbodykit-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# download the data to the current directory\n",
    "download_dir = \"catalogs\"\n",
    "download_data(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: change this path if you downloaded the data somewhere else!\n",
    "# data_path = os.path.join(download_dir, 'galaxy_DR12v5_LOWZ_South.fits')\n",
    "# randoms_path = os.path.join(download_dir, 'random0_DR12v5_LOWZ_South.fits')\n",
    "# data_path = os.path.join(download_dir, 'galaxy_DR12v5_CMASSLOWZTOT_North.fits')\n",
    "# randoms_path = os.path.join(download_dir, 'random0_DR12v5_CMASSLOWZTOT_North.fits')\n",
    "data_path = os.path.join(download_dir, 'galaxy_DR12v5_CMASSLOWZTOT_South.fits')\n",
    "randoms_path = os.path.join(download_dir, 'random0_DR12v5_CMASSLOWZTOT_South.fits')\n",
    "\n",
    "# initialize the FITS catalog objects for data and randoms\n",
    "data = FITSCatalog(data_path)\n",
    "randoms = FITSCatalog(randoms_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the available columns in the catalogs via the ``columns`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data columns = ', data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('randoms columns = ', randoms.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the catalogs exactly as in our $P(k)$ measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZMIN = 0.2\n",
    "ZMAX = 0.43\n",
    "# ZMIN = 0.43\n",
    "# ZMAX = 0.7\n",
    "\n",
    "# slice the randoms\n",
    "valid = (randoms['Z'] > ZMIN)&(randoms['Z'] < ZMAX)\n",
    "randoms = randoms[valid]\n",
    "\n",
    "# slice the data\n",
    "valid = (data['Z'] > ZMIN)&(data['Z'] < ZMAX)\n",
    "data = data[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fiducial BOSS DR12 cosmology\n",
    "cosmo = cosmology.Cosmology(h=0.676).match(Omega0_m=0.31)\n",
    "\n",
    "# add Cartesian position column\n",
    "data['Position'] = transform.SkyToCartesian(data['RA'], data['DEC'], data['Z'], cosmo=cosmo)\n",
    "randoms['Position'] = transform.SkyToCartesian(randoms['RA'], randoms['DEC'], randoms['Z'], cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms['WEIGHT'] = 1.0\n",
    "data['WEIGHT'] = data['WEIGHT_SYSTOT'] * (data['WEIGHT_NOZ'] + data['WEIGHT_CP'] - 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong normalization $A_\\Sigma$ from standard nbodykit $P(k)$ measurements pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a mesh and computes the power spectrum multipoles of BOSS.  \n",
    "This operation will give us the `wrong' normalization, $A_\\Sigma$, that we can compare to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the data and randoms into a single catalog\n",
    "fkp = FKPCatalog(data, randoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we care only getting the `wrong' normalization, \n",
    "# here we just put minimal options so that the two following operations are fast\n",
    "mesh = fkp.to_mesh(Nmesh=16, BoxSize=3500., \n",
    "    nbar='NZ', fkp_weight='WEIGHT_FKP', comp_weight='WEIGHT', resampler='NEAREST', interlaced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ConvolvedFFTPower(mesh, poles=[0], kmin=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in r.attrs:\n",
    "    print(\"%s = %s\" % (key, str(r.attrs[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.norm / randoms.norm above are $A_\\Sigma$. We call it `I22` in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I22 = r.attrs['randoms.norm']\n",
    "alpha = r.attrs['alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong normalization $A_\\Sigma$  from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute $A_\\Sigma$ ourself now: \n",
    "\n",
    "\\begin{equation}\n",
    "A_\\Sigma = \\sum_i^{N_p} \\bar n_i w_i^2 \\ ,\n",
    "\\end{equation}\n",
    "\n",
    "We are going to use *nbodykit* internal functions to make sure they do what we think they do. We furthermore put the $N_p$ objects of the (random) catalog on a grid to make sure that the grid is not making anything weird. \n",
    "\n",
    "But first let us do it ourself at the level of the catalog to make sure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = np.sum(data['NZ'].compute() * data['WEIGHT'].compute() * data['WEIGHT_FKP'].compute()**2)\n",
    "norm_randoms = np.sum(randoms['NZ'].compute() * randoms['WEIGHT'].compute() * randoms['WEIGHT_FKP'].compute()**2)\n",
    "\n",
    "print ('%.3f' % (norm_data / I22))\n",
    "print ('%.3f' % (alpha * norm_randoms / I22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do it with *nbodykit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms['WEIGHT_FKP_squared'] = 1. * randoms['WEIGHT_FKP']**2\n",
    "randoms['WEIGHT_squared'] = 1. * randoms['WEIGHT']**2 * randoms['NZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkp = FKPCatalog(randoms, None, BoxPad=0.) \n",
    "# fkp = FKPCatalog(data, None, BoxPad=0.) ### fast but with cosmic variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmesh, Lbox = 128, 3500. # this is whatever, as long as the box is large enough\n",
    "mesh = fkp.to_mesh(Nmesh=Nmesh, BoxSize=Lbox, \n",
    "                   nbar='NZ', fkp_weight='WEIGHT_FKP_squared', comp_weight='WEIGHT_squared', \n",
    "                   resampler='NEAREST', interlaced=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D field of $n w^2$ in configuration space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw2 = mesh.to_real_field() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum over the whole box in configuration space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muedges = np.linspace(-1, 1, 2, endpoint=True)\n",
    "xedges = np.array([0., Lbox]) \n",
    "edges = [xedges, muedges]\n",
    "\n",
    "### result = (xmean_2d, mumean_2d, y2d, N_2d)\n",
    "proj_result, _ = project_to_basis(nw2, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that we get the same: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = alpha * np.real(np.squeeze(proj_result[2])) * Lbox**3\n",
    "print ('%.3f' % (norm / I22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the factor of $\\alpha^1$ is to rescale our results to the correct one as we use $1$ random field.  \n",
    "the factor of $V = L_{\\rm box}^3$ is what *nbodykit* does, so I do it. \n",
    "\n",
    "Notice that we get the same is really a good check: *nbodykit* really does the sum over the objects in the catalogs, while I instead put the re-weighted objects on a grid first then summed the cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other possibility to perform the sum is simply to Fourier transform the configuration-space field $nw^2$ and take the $0$-mode of the Fourier field: \n",
    "\n",
    "\\begin{equation}\n",
    "A_\\Sigma = \\lim_{k\\rightarrow 0} \\sum_i \\ e^{-ik r} n_i w_i^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw2_k = nw2.r2c() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the same from the Fourier $0$-mode: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = alpha * np.real(nw2_k[0,0,0]) * Lbox**3\n",
    "print ('%.3f' % (norm / I22)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us do $A_{k\\rightarrow 0}$ now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to take a box big enough to make sure that we have all the modes.  \n",
    "We alse need to take thin enough cells to resolve the modes down to the scales where the `window' is constant (just acting like an identity function).  \n",
    "Therefore, this operation might be memory-intensive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmesh, Lbox = 256, 2000. # on my laptop I can not take too big Nmesh\n",
    "mesh = fkp.to_mesh(Nmesh=Nmesh, BoxSize=Lbox, \n",
    "    nbar='NZ', fkp_weight='WEIGHT_FKP', comp_weight='WEIGHT', \n",
    "    compensated=True, resampler='tsc', interlaced=True) \n",
    "# now we want to throw in some good options to resolve as deep as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D field of $w$ in configuration space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = mesh.to_real_field() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tempting to first multiply $w$ by itself in configuration space then Fourier transform and look the Fourier $0$-mode as our definition of $A_{k\\rightarrow 0}$ suggests:\n",
    "\n",
    "\\begin{equation}\\label{eq:real}\n",
    "A_{k\\rightarrow 0} = \\lim_{k\\rightarrow 0} \\int d^3 r \\ e^{-ikr} n_w(r)^2\n",
    "\\end{equation}\n",
    "\n",
    "However, this operation is UV sensitive, and importantly, not in the same way as the way we measure the power spectrum!\n",
    "\n",
    "Indeed, for the power spectrum, we instead take the product of the fields in Fourier space. \n",
    "\n",
    "Therefore, we should instead use the convolution formulation: \n",
    "\n",
    "\\begin{equation}\\label{eq:fourier}\n",
    "A_{k\\rightarrow 0} = \\lim_{k\\rightarrow 0} \\int d^3 p \\ \\tilde n_w(p-k) \\tilde n_w(p) = \\int d^3 p \\ \\tilde n_w(p)^2 \\ ,\n",
    "\\end{equation}\n",
    "\n",
    "where the products of the field are taken in Fourier space consistently with the way we measure the power spectrum. \n",
    "\n",
    "Still, let us first do the calculation where we square the field in configuration space to see what we get and then compare to the calculation where we square the field in Fourier space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $A$ from squaring the configuration-space field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall not forget to compensate for the interpolation kernels. \n",
    "\n",
    "So Let's Fourier transform first the $w$ field, compensate, then Fourier transform back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_k = w.r2c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compensation(mesh):\n",
    "    toret = None\n",
    "    try:\n",
    "        compensation = mesh._get_compensation()\n",
    "        toret = {'func':compensation[0][1], 'kind':compensation[0][2]}\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return toret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compensation = get_compensation(mesh)\n",
    "print (compensation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_k = w_k.apply(out=Ellipsis, **compensation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier transforming back: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = wc_k.c2r()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squaring in configuration space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc2_direct = 1.*wc\n",
    "for islab in range(wc.shape[0]):\n",
    "    wc2_direct[islab,...] = wc[islab]*wc[islab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doing the integral over the whole configuration space by taking the $0$-mode in the reciprocal space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc2_direct_k = wc2_direct.r2c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = alpha**2 * np.real(wc2_direct_k[0,0,0]) * Lbox**3 # now it is alpha^2 because we have two randoms fields\n",
    "print ('norm=%.3f, ratio=%.3f' % (norm, norm / I22)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $A$ from squaring the Fourier-space field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instead take the product of $w$ in Fourier space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc2_k = 1.*wc_k\n",
    "for islab in range(wc_k.shape[0]):\n",
    "    wc2_k[islab,...] = wc_k[islab]*wc_k[islab].conj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally to perform the integral over the whole Fourier space we may use the trick where we take the $0$-mode of the reciprocal space: \n",
    "\n",
    "\\begin{align}\n",
    "A_{s\\rightarrow 0} & = \\lim_{s\\rightarrow 0} \\int d^3 p \\ e^{iks} \\tilde n_w(p)^2 \\\\\n",
    " & = \\lim_{s\\rightarrow 0} \\int d^3 r \\ n_w(r-s) n_w(r) \\\\\n",
    " & = \\int d^3 r \\ n_w(r)^2 \\ ,\n",
    "\\end{align}\n",
    "\n",
    "Notice that this exactly the way that we have already computed $A_{s\\rightarrow 0}$ through the window functions!\n",
    "\n",
    "Let us then Fourier transform back $\\tilde w^2$ to configuration space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc2 = wc2_k.c2r()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norm from configuration-space $0$-mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = alpha**2 * np.real(wc2[0,0,0]) * Lbox**3 # now it is alpha^2 because we have two randoms fields\n",
    "print ('norm=%.3f, ratio=%.3f' % (norm, norm / I22)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('ratio real squared vs. Fourier squared = %.3f' % (np.real(wc2_direct_k[0,0,0]/wc2[0,0,0]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good so far, though, it is not the right answer... Why?\n",
    "\n",
    "The correct normalization can not be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `right' answer (the one I get from the window functions) is $A_{\\rm right}/A_{\\rm wrong} \\equiv A_{s\\rightarrow 0} / A_\\Sigma \\sim 0.88 \\pm 0.01$. \n",
    "\n",
    "- Nmesh, Lbox = 256, 2000.: norm=2.145, ratio=1.062 <-- too big  \n",
    "- Nmesh, Lbox = 256, 3000.: norm=1.932, ratio=0.956 <-- still too big, we are still not taking enough large box??? \n",
    "(Indeed, when getting the normalization through the window function, I actually take a box of Lbox = 100000...)  \n",
    "- Nmesh, Lbox = 256, 10000.: norm=1.783, ratio=0.883 <-- for LOWZ SGC, could it be that we are taking large enough box now??? \n",
    "- Nmesh, Lbox = 256, 10000.: norm=1.844, ratio=0.913 <-- Mmmh, looks like this is not about being not large enough, rather we were cutting modes from the deep regime where the window is constant..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as expected, the results are quite dependent on if we are able to include all modes in the box (large `Lbox`) and resolve enough the UV (large `Nmesh`). We should at least the same range that I do when I am getting the normalization through the window function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last comments..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Maybe we should take care first of the shot noise (of the randoms) that will shift the value of \n",
    "$A_{s\\rightarrow 0} = \\lim_{s\\rightarrow 0} \\int d^3 p \\ e^{iks} \\tilde n_w(p)^2$ up. \n",
    "\n",
    "2. My fear is that we are sensitive to the junk $k>k_{\\rm Nyq}$ in this procedure. This could explain why the get a too big normalization! (indeed in the computation through the window function I make sure to remove the junk in $Q(k)$ before integrating over to get the normalization).  \n",
    "\n",
    "Therefore, we should not use the $0$-mode trick to do the integral over the Fourier space but stay in Fourier and do the integral in the region that we trust, that is, $k \\in [k_f, \\sim k_{\\rm Nyq}]$, with $k_f = 2pi/L_{\\rm box}, k_{\\rm Nyq} = \\pi N_{\\rm mesh}/L_{\\rm box}$. \n",
    "\n",
    "Let us do that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muedges = np.linspace(-1, 1, 2, endpoint=True)\n",
    "kf, knyq = 2*np.pi / Lbox, np.pi * Nmesh / Lbox\n",
    "print (kf, knyq)\n",
    "# xedges = np.array([kf, knyq])\n",
    "xedges = np.array([0, knyq*1000.]) ### for now let me just try to reproduce the $0$-mode results\n",
    "edges = [xedges, muedges]\n",
    "\n",
    "### result = (xmean_2d, mumean_2d, y2d, N_2d)\n",
    "proj_result, _ = project_to_basis(wc2_k, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = alpha**2 * np.real(np.squeeze(proj_result[2])) * Lbox**3\n",
    "print ('%.3f' % (norm / I22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_0 = alpha**2 * np.real(wc2[0,0,0]) * Lbox**3 # 0-mode results\n",
    "norm_int = alpha**2 * np.real(np.squeeze(proj_result[2])) * (Lbox**3)**2 / (2*np.pi)**3 \n",
    "# there are some factors here that I don't know, just putting random stuff now to try to get something reasonable\n",
    "print (norm_int/norm_0) # OK this should work with the right factors!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is clear let us go the super-computer to crank up `Nmesh`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
